---
title: "FeatureSelection"
author: "Jake Daniels"
date: "July 18, 2018"
output: html_document
---

# Part 3) Feature Selection

Pre-feature selection model

0.1 Necessary Packages
```{r}
#install.packages("caret") - for preProcess
#install.packages("e1071") - for confusionMatrix
#install.packages("pROC") - for ROC
#install.packages("RWeka") - for RWeka
library(caret)
library(e1071)
library(lattice) # might not need cuz caret autoloads
library(pROC)
library(RWeka)
```
Loading packages from part 2 cleaning
```{r}
library(tidyverse)
library(gmodels)
library(plotly)
library(reshape2)
```

0.2 Basic Model with cleaned data to compare to after we model with Feature Selection

Splitting data into 75% training 25% test
```{r}
tele_clean$Customer_ID <- NULL
index_train <- sample(1:nrow(tele_clean), 3/4 * nrow(tele_clean))
basic_training_set <- tele_clean[index_train, ]
basic_test_set <- tele_clean[-index_train, ]
```
R - Logistic
```{r}
set.seed(1)
basic_model <- glm(churn ~ ., family = "binomial", data = basic_training_set)
basic_predictions <- predict(basic_model, newdata = basic_test_set, type = "response")

# Make a binary predictions-vector using a cut-off of 50%
  basic_pred_cutoff <- ifelse(basic_predictions > 0.5, 1, 0)

# Construct a confusion matrix
  basic_conf_matrix <- table(basic_test_set$churn, basic_pred_cutoff) %>% confusionMatrix()
basic_conf_matrix

# Sensitivity = True Positive Rate
# Specificity = False Positive Rate
```
Visualizing
```{r}
# quickly evaluating with ROC function
mplot_roc <- function(tag, score, model_name = NA, subtitle = NA, interval = 0.2, plotly = FALSE,
save = FALSE, file_name = "viz_roc.png") {
  require(pROC)
  require(ggplot2)

  if (length(tag) != length(score)) {
    message("The tag and score vectors should be the same length.")
    stop(message(paste("Currently, tag has",length(tag),"rows and score has",length(score))))
  }

  roc <- pROC::roc(tag, score, ci=T)
  coords <- data.frame(
    x = rev(roc$specificities),
    y = rev(roc$sensitivities))
  ci <- data.frame(roc$ci, row.names = c("min","AUC","max"))

  p <- ggplot(coords, aes(x = x, y = y)) +
    geom_line(colour = "deepskyblue", size = 1) +
    geom_point(colour = "blue3", size = 0.9, alpha = 0.4) +
    geom_segment(aes(x = 0, y = 1, xend = 1, yend = 0), alpha = 0.2, linetype = "dotted") + 
    scale_x_reverse(name = "% Specificity [False Positive Rate]", limits = c(1,0), 
                    breaks = seq(0, 1, interval), expand = c(0.001,0.001)) + 
    scale_y_continuous(name = "% Sensitivity [True Positive Rate]", limits = c(0,1), 
                       breaks = seq(0, 1, interval), expand = c(0.001, 0.001)) +
    theme_minimal() + 
    theme(axis.ticks = element_line(color = "grey80")) +
    coord_equal() + 
    ggtitle("ROC Curve: AUC") +
    annotate("text", x = 0.25, y = 0.10, vjust = 0, size = 4.2, 
             label = paste("AUC =", round(100*ci[c("AUC"),],2))) +
    annotate("text", x = 0.25, y = 0.05, vjust = 0, size = 2.8, 
             label = paste0("95% CI: ", 
                            round(100*ci[c("min"),],2),"-", 
                            round(100*ci[c("max"),],2)))
  if(!is.na(subtitle)) {
    p <- p + labs(subtitle = subtitle)
  }  

  if(!is.na(model_name)) {
    p <- p + labs(caption = model_name)
  }

  if (plotly == TRUE) {
    require(plotly)
    p <- ggplotly(p)
  }

  if (save == TRUE) {
    p <- p + ggsave(file_name, width = 6, height = 6)
  }
  return(p)
}

model_name <- paste("glm(churn ~ ., family = 'binomial', data = basic_training_set)")
subtitle <- paste("Logistic Regression in R - ALL Variables")  
mplot_roc(basic_test_set$churn, basic_predictions, model_name = model_name, subtitle = subtitle)
```
# Dimensionality Reduction 

1.1 Filtering Rows

Determining Outliers - beyond 99 percentile of confidence
```{r}
library(outliers)

rows_chisq <- scores(tele_clean,type="chisq", prob=0.999) %>%
  summarise_all(funs(sum)) 

rows_zscore <- scores(tele_clean,type="z", prob=0.999) %>%
  summarise_all(funs(sum))

# table for comparison
rows_comparison<-rbind(rows_chisq, rows_zscore)
  row.names(rows_comparison) <- c("chisq", "z-score")

rows_comparison

# choosing z-score because I will normalize my data in z-scores for modelling
tele_clean[which(rowSums(rows_zscore, na.rm = T) >=5),] <- NA
tele_clean_rows <- tele_clean[which(!is.na(tele_clean$drop_vce_Mean)),]
```

2.1 Filter Variables
Normalizing then identifying low variance attributes
```{r}
# normalizing function with z-scores
normFunc <- function(x){(x-mean(x, na.rm = T))/sd(x, na.rm = T)}

# pulling all numerics out of set
nums <- unlist(lapply(tele_clean_rows, is.numeric)) 
# applying formula
normalized <- sapply(tele_clean_rows[,nums], normFunc) %>% as.data.frame()
```

```{r}
# examing distributions for low variance (limited to absolute 3 to negate extreme values)
melt(normalized[,1:12]) %>%
  filter(abs(value) <= 3) %>%
ggplot(aes(x=value)) +
  stat_ecdf() +
  facet_wrap(~variable, scales = "free") +
  theme_bw()
#datovr
```

```{r}
melt(normalized[,13:24]) %>%
  filter(abs(value) <= 3) %>%
ggplot(aes(x=value)) +
  stat_ecdf() +
  facet_wrap(~variable, scales = "free") +
  theme_bw()
#roam_Mean
```

```{r}
melt(normalized[,25:36]) %>%
  filter(abs(value) <= 3) %>%
ggplot(aes(x=value)) +
  stat_ecdf() +
  facet_wrap(~variable, scales = "free") +
  theme_bw()
#comp_data_Mean
#mou_compdata_Mean
```

```{r}
melt(normalized[,37:48]) %>%
  filter(abs(value) <= 3) %>%
ggplot(aes(x=value)) +
  stat_ecdf() +
  facet_wrap(~variable, scales = "free") +
  theme_bw()
#peak_data_Mean
#mou_peak_data_Mean
#opk_data_Mean
#mou_opk_data_Mean
#callfwdv_Mean
```
```{r}
melt(normalized[,49:60]) %>%
  filter(abs(value) <= 3) %>%
ggplot(aes(x=value)) +
  stat_ecdf() +
  facet_wrap(~variable, scales = "free") +
  theme_bw()
#drop_data_Mean
```

```{r}
melt(normalized[,61:71]) %>%
  filter(abs(value) <= 3) %>%
ggplot(aes(x=value)) +
  stat_ecdf() +
  facet_wrap(~variable, scales = "free") +
  theme_bw()
#blck_data_Mean
#unan_data_Mean
#plcd_data_Mean
#recv_sms_Mean
```
My Selections of Low Variance Variables to drop based on observations
```{r}
# my list
low_variance <- c("datovr_Mean", "roam_Mean", "comp_data_Mean", "mou_compdata_Mean", "peak_data_Mean", "mou_peak_data_Mean", "opk_data_Mean", "mou_opk_data_Mean", "callfwdv_Mean", "drop_data_Mean", "blck_data_Mean", "unan_data_Mean", "plcd_data_Mean", "recv_sms_Mean")
```
2.2 Near-Zero Variance processing with Caret
```{r}
library(caret)
caret_low_variance<- preProcess(x=normalized, method = c("nzv"))

# examining the list of variables it dropped
caret_low_variance$method$remove

# showing my list
low_variance
```

3.1 Correlations
Strongest Correlations related to Churn - Pearson vs Spearman
```{r}
normalized$churn <- tele_clean_rows$churn %>% as.numeric()

# pearson 
nums <- unlist(lapply(normalized, is.numeric))  
Cl <- cor(normalized[,nums], method = "pearson")
Cl <- ifelse(Cl > 0, Cl^.5, -abs(Cl)^.5)
Cl <- as.data.frame(Cl)
df1<- Cl %>%
  select(churn) %>%
  mutate(variable = names(Cl)) %>%
  arrange(desc(churn))

# spearman
ClS <- cor(normalized[,nums], method = "spearman")
ClS <- ifelse(ClS > 0, ClS^.5, -abs(ClS)^.5)
ClS <- as.data.frame(ClS)
df2<-ClS %>% 
  select(churn) %>%
  mutate(variable = names(ClS)) %>%
  arrange(desc(churn))

# looking at side by side
correlations <- merge(df1,df2, by = "variable")
names(correlations) <- c("variable", "pearson", "spearman")
correlations_ordered <- correlations %>%
  mutate(variable = variable, pearson = abs(pearson), spearman = abs(spearman)) %>%
  filter(variable != "churn") %>%
  arrange(desc(spearman))
 
# 15 highest 
correlations_ordered[1:15,]

# bottom 5
correlations_ordered[67:71,]
```
3.2 Using caret to identify multicolinearity (highly correlated variables)
```{r}
library(caret)
caret_high_correlation<- preProcess(x=normalized, method = c("corr"))

caret_high_correlation$method$remove
```
3.3 using rms to examine variance inflation and identify correlated variables
```{r}
install.packages("rms")
library(rms)
vif(normalized)
# looking at variance inflation anything  > 10 is bad
```

4.1 Using Weka's InfoGain on churn to examine impactful variables
```{r}
# adding factors back in to normalzed set 
factors <- unlist(lapply(tele_clean_rows, is.factor))
final_set <- cbind(normalized[,-72], tele_clean_rows[,factors])

# infogain top attributes
churn_wekainfo <- InfoGainAttributeEval(churn ~ . , data = final_set)
churn_infogain <- as.data.frame(churn_wekainfo) %>%
  mutate(variable = names(final_set[,-73]), churn_wekainfo = churn_wekainfo*100) %>%
  arrange(desc(churn_wekainfo))

churn_infogain
```

4.2 Visualizing top results
```{r}
model_name <- paste("Weka - InfoGainAttributeEval")
subtitle <- paste("Top 15 Variables Ranked on Importance by InfoGainAttributeEval")
mplot_importance <- function(var, imp, colours = NA, limit = 15, model_name = NA, subtitle = NA,
                             save = FALSE, file_name = "viz_importance.png", subdir = NA) {
  
  require(ggplot2)
  require(gridExtra)
  options(warn=-1)
  
  if (length(var) != length(imp)) {
    message("The variables and importance values vectors should be the same length.")
    stop(message(paste("Currently, there are",length(var),"variables and",length(imp),"importance values!")))
  }
  if (is.na(colours)) {
    colours <- "deepskyblue" 
  }
  out <- data.frame(var = var, imp = imp, Type = colours)
  if (length(var) < limit) {
    limit <- length(var)
  }
  
  output <- out[1:limit,]
  
  p <- ggplot(output, 
              aes(x = reorder(var, imp), y = imp * 100, 
                  label = round(100 * imp, 1))) + 
    geom_col(aes(fill = Type), width = 0.1) +
    geom_point(aes(colour = Type), size = 6) + 
    coord_flip() + xlab('') + theme_minimal() +
    ylab('Importance') + 
    geom_text(hjust = 0.5, size = 2, inherit.aes = TRUE, colour = "white") +
    labs(title = paste0("Variable Importances. (", limit, " / ", length(var), " plotted)"))
  
  if (length(unique(output$Type)) == 1) {
    p <- p + geom_col(fill = colours, width = 0.2) +
      geom_point(colour = colours, size = 6) + 
      guides(fill = FALSE, colour = FALSE) + 
      geom_text(hjust = 0.5, size = 2, inherit.aes = TRUE, colour = "white")
  }
  if(!is.na(model_name)) {
    p <- p + labs(caption = model_name)
  }
  if(!is.na(subtitle)) {
    p <- p + labs(subtitle = subtitle)
  }  
  if(save == TRUE) {
    if (!is.na(subdir)) {
      dir.create(file.path(getwd(), subdir))
      file_name <- paste(subdir, file_name, sep="/")
    }
    p <- p + ggsave(file_name, width=7, height=6)
  }
  
  return(p)
  
}

mplot_importance(churn_infogain$variable,churn_infogain$churn_wekainfo, model_name=model_name, subtitle=subtitle)
```
```{r}
install.packages("Boruta")
library(Boruta)
# Decide if a variable is important or not using Boruta
boruta_output <- Boruta(churn ~ ., data=final_set, doTrace=2)  # perform Boruta search
# Confirmed 10 attributes: Humidity, Inversion_base_height, Inversion_temperature, Month, Pressure_gradient and 5 more.
# Rejected 3 attributes: Day_of_month, Day_of_week, Wind_speed.
boruta_signif <- names(boruta_output$finalDecision[boruta_output$finalDecision %in% c("Confirmed", "Tentative")])  # collect Confirmed and Tentative variables
print(boruta_signif)  # significant variables
#=> [1] "Month"                 "ozone_reading"         "pressure_height"      
#=> [4] "Humidity"              "Temperature_Sandburg"  "Temperature_ElMonte"  
#=> [7] "Inversion_base_height" "Pressure_gradient"     "Inversion_temperature"
#=> [10] "Visibility"
plot(boruta_output, cex.axis=.7, las=2, xlab="", main="Variable Importance") 

#blck_data_Mean, callfwdv_Mean, ethnic, forgntvl, kid0_2, +7, new_cell, kid11_15,kid16_17, drop_data_Mean
#rejected 1 attribute: new_cell;
#rejected 2 attributes: kid11_15, kid16_17;
#rejected 1 attribute: drop_data_Mean;
#rejected 1 attribute: income
```

5.1 Dropping the identified variables
```{r}
# variables to remove from high corr - 21 variables
removed <- caret_high_correlation$method$remove

# variables to remove from low variance -21 variables
removed2 <- caret_low_variance$method$remove

# variables to remove from low infogain, arbiturarily chose 0.02 - 18 variables
removed3 <- churn_infogain %>%
  filter(churn_wekainfo <0.02) %>%
  select(variable) %>%
  unlist()

# making final model
final_set[,removed] <- NULL
final_set[,removed2] <- NULL
final_set[,removed3] <- NULL
```

```{r}
write_csv(final_set, "final_set.csv")
```