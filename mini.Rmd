---
title: "mini"
author: "Jake Daniels"
date: "July 23, 2018"
output: html_document
---


```{r}
low_cost <- tele[which(round(tele$hnd_price,2) == 29.99),]
```

```{r}
# we predicted would stay but left, FALSE POS
unsatisfied <- prediction_set %>%
  filter(Stayed > 0.7 & Actual == 1) 
```

Identifying our at-risk customers our model has >70% chance of leaving
```{r}
# creating data frame of predictions and outcomes, 24,777 records
prediction_set <- Weka_forest_predictions %>%
  as.data.frame() %>%
  mutate( Customer = row.names(validation), Stayed = Weka_forest_predictions[,1], Churned = Weka_forest_predictions[,2], Actual = validation$churn) %>%
  select(Customer, Stayed, Churned, Actual) 

head(prediction_set)
```
```{r}
# subsetting the customers we predicted to churn but stayed, currently at-risk
at_risk_subset <- prediction_set %>%
  filter(Churned > 0.7)
prediction_set %>%
  filter(Churned > 0.7 & Actual == 0)

# 254 True Negatives (predicted to leave but are still here) from my current model,254/1014 predicted to be FP, rate = 25%

# take all customers that were >70% risk, put all their data into the set
full_70 <- validation[at_risk_subset$Customer,]
summary(full_70)

#write.arff(full_70, "full_70.arff")
```

```{r}
# split into a new train/test
index_train1 <- sample(1:nrow(full_70), 3/4 * nrow(full_70))
basic_training_set1 <- full_70[index_train1, ]
basic_test_set1 <- full_70[-index_train1, ]
```

```{r}
# original

Weka_forest_predictions22 <- predict(Weka_forest_model, newdata = basic_test_set1, type = "probability")
Weka_forest_pred_cutoff_5022 <- ifelse(Weka_forest_predictions22[,2] > 0.7, 1, 0)

Weka_forest_conf_matrix_5022 <- table(basic_test_set1$churn, Weka_forest_pred_cutoff_5022) %>% confusionMatrix(positive='1')
Weka_forest_conf_matrix_5022

```

```{r}
WekaForest <- make_Weka_classifier("weka/classifiers/trees/RandomForest")
model_70 <- WekaForest(churn ~ ., data=basic_training_set1)
model_70_predictions <- predict(model_70, newdata = basic_test_set1, type = "probability")

# Make a binary predictions-vector using a cut-off of 50%
  basic_pred_cutoff1 <- ifelse(model_70_predictions[,2] > 0.7, 1, 0)

# Construct a confusion matrix
  basic_conf_matrix1 <- table(basic_test_set1$churn, basic_pred_cutoff1) %>% confusionMatrix()
basic_conf_matrix1


model_70_prediction_set <- model_70_predictions %>%
  as.data.frame() %>%
  mutate(Customer = row.names(basic_test_set1), ChurncHANCE = model_70_predictions[,2], Actual = basic_test_set1$churn) %>%
  select(Customer, ChurncHANCE, Actual) 

head(model_70_prediction_set)

model_70_prediction_set %>%
  filter(ChurncHANCE > 0.7 & Actual == 0)

# only 48 False Negatives when isolating this, 48/254, 18% FP rate, down from 25%

mplot_roc(basic_test_set1$churn, model_70_predictions[,2])

```

```{r}

#install.packages("gghighlight")
library(tidyverse)
library(gghighlight)

prediction_set$eqpdays <- validation[prediction_set$Customer,]$eqpdays

prediction_set %>%
  as.data.frame() %>%
  ggplot()+
  geom_point(aes(x=Customer,y = eqpdays))+
  gghighlight(Churned > 0.7 & Actual == 0, use_direct_label = FALSE) +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) + 
  xlab("Customers") +
  geom_hline(yintercept = median(prediction_set$eqpdays)) +
  geom_hline(yintercept = median(prediction_set[which(prediction_set$Churned > 0.7 & prediction_set$Actual == 0),]$eqpdays), color = "red")

# if they meet the threshold, and their equipment days are > 0.162182569095626 Z-score
paste(median(prediction_set[which(prediction_set$Churned > 0.7 & prediction_set$Actual == 0),]$eqpdays))


```
```{r}
prediction_set$test <- validation[prediction_set$Customer,]$iwylis_vce_Mean

prediction_set %>%
  as.data.frame() %>%
  ggplot()+
  geom_point(aes(x=Customer,y = test))+
  gghighlight(Churned > 0.7 & Actual == 0, use_direct_label = FALSE) +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) + 
  xlab("Customers") +
  geom_hline(yintercept = mean(prediction_set$test)) +
  geom_hline(yintercept = mean(prediction_set[which(prediction_set$Churned > 0.7 & prediction_set$Actual == 0),]$test), color = "red")


```

```{r}
at_risk_subset <- validation[at_risk$Customer,]
```

```{r}

#summary(at_risk_subset)

write.arff(tele_clean, "tele_clean.arff")

saveRDS(Weka_forest_model, "./Weka_forest_model.rds")
 
# load the model
final_model <- readRDS("./Weka_forest_model.rds")
print(final_model)
# make a predictions on "new data" using the final model
final_predictions <- predict(Weka_forest_model, tele_clean, type = "probability")
confusionMatrix(final_predictions, validation$Class, positive='1')

Weka_forest_predictions <- predict(final_model, newdata = validation)
Weka_forest_pred_cutoff_50 <- ifelse(Weka_forest_predictions[,2] > 0.5, 1, 0)

Weka_forest_conf_matrix_50 <- table(validation$churn, Weka_forest_pred_cutoff_50) %>% confusionMatrix(positive='1')
Weka_forest_conf_matrix_50
```

```{r}
temp1 <- at_risk_subset[,1:37] %>%
  mutate(churn = as.numeric(churn)) %>%
  cor() %>%
  as.data.frame() 

temp1 %>%
  mutate(variable = row.names(temp1)) %>%
  select(variable, churn) %>%
  arrange(desc(churn))
  

write.arff(at_risk_subset, "at_risk.arff")
```

```{r}
write.arff(tele_clean, "tele_clean.arff")
```
```{r}

explore_clean <- tele_clean_rows
explore_clean$eqpdaysbin <- cut(explore_clean$eqpdays, breaks = seq(0,1900, by=60))

explore_clean %>%
  select(eqpdays, eqpdaysbin, churn) %>%
  mutate(ID = 1:99107) %>%
  ggplot()+
  geom_point(aes(x=eqpdaysbin,y=eqpdays)) +
  gghighlight(churn == 1 , use_direct_label = FALSE) +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) + 
  xlab("Customers") +
  geom_hline(yintercept = median(tele_clean$eqpdays)) +
  geom_hline(yintercept = median(tele_clean[which(tele_clean$churn == 1),]$eqpdays), color = "red")


tele_clean_rows[1:100,]  %>%
  ggplot()+
  geom_point(aes(x=Customer_ID, y=eqpdays)) +
  gghighlight(Churned > 0.7 & Actual == 0, use_direct_label = FALSE) +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) + 
  xlab("Customers") +
  geom_hline(yintercept = median(prediction_set$eqpdays)) +
  geom_hline(yintercept = median(prediction_set[which(prediction_set$Churned > 0.7 & prediction_set$Actual == 0),]$eqpdays), color = "red")


```

One way to quantify the accuracy of a predictive model is by calculating its lift,
e.g., among say the 10% of customers predicted as most likely to churn, what percentage
of them actually do, relative to the percentage of all customers who churn. The higher
the lift, the more accurate the model, and intuitively, the more profitable a targeted
proactive churn management program will be. In this section, we formulate profitability
as a function of lift, and perform calculations to assess the potential value of increased lift
in practice. We first define the following terms:

N = Total number of customers.
```{r}
N = 100000
```

α = Fraction of customers who are targeted for the churn management
program.
```{r}
α = 0.10
```

β = Fraction of targeted customers who are in fact would-be churners.
```{r}
B0 = 0.4932
```

δ = Cost of the customer incentive to the firm. E.g., if the company offers
customers a $50 rebate, the cost is $50.
```{r}
δ = 50
```
γ = Fraction of targeted would-be churners who are wooed back to the
company by the incentive, i.e., the success rate of the incentive.
```{r}
Y = 0.1 
Y2 = 0.3
Y3 = 0.5 
```

c = Cost of contacting a customer to offer him or her the incentive.
```{r}
c = 0.50
```

LVC = Lifetime value of the customer, i.e., the value of the customer to the
firm if the customer is retained.
```{r}
LVC = 1500  
LVC2 = 2500
LVC3 = 4000
```

П = Profit contributed by the churn management program.

Given these definitions, the profit contributed by the churn management program is:
П = Nα{ βγ(LVC-c-δ) + β(1-γ)(-c) + (1-β)(-c-δ) } (1)
```{r}
П = N*α{ (Y*LVC+δ(1-Y))B0*λ - δ - c }
```

```{r}
data.frame(obs =Weka_forest_pred_cutoff_50)
           


#x.model <-  Weka_forest_mode
# Alternatively, use "recursive partitioning [...] in a conditional
# inference framework."
# x.model <- ctree(Kyphosis ~ Age + Number + Start, data=x.train)
 
# ctree plots nicely (but cforest doesn"t plot)
# plot (x.model)
x.model <- cforest(churn ~ ., data=final_training_set,
control = cforest_unbiased(mtry = 3))
# Use the model to predict the evaluation.
validation$prediction <- predict(x.model, newdata=validation)


# Extract the class probabilities.
validation$probabilities <- 1- unlist(treeresponse(x.model,newdata=validation), use.names=F)[seq(1,nrow(validation)*2,2)]

validation$probabilities <- predict(Weka_forest_model, newdata = validation, type = "probability")
# Plot the performance of the model applied to the evaluation set as
# an ROC curve.
require(ROCR)
tele_clean$holdoutcome <- ifelse(tele_clean$holdoutpred > 0.5, 1,0)
pred <- prediction(tele_clean$holdoutpred, tele_clean$churn)
perf <- performance(pred,"tpr","fpr")
plot(perf, main="ROC curve", colorize=T)
 
# And then a lift chart
perf <- performance(pred,"lift","rpp")
plot(perf, main="lift curve", colorize=T)

# Calculate the overall accuracy.
tele_clean$correct <- tele_clean$holdoutcome == tele_clean$churn
print(paste("% of predicted classifications correct", mean(tele_clean$correct)))
```



LVC = $1500, $2500, $4000. Monthly revenues per customer for the
typical telecommunications company are in the $40-$60 range. If
we use $40, a monthly churn rate of 1.8%, and a 5% annual
discount rate, the lifetime value of the customer is $1812.

A heavy user customer might spend $100 per month, which would result in
an LVC of $4530. We use the values $1500, $2500, and $4000 as
reasonable numbers for our illustrative calculations.

The first term within the brackets reflects profit contribution among the βγ fraction ofcontacted customers who are would-be churners and decide based on the incentive to stay
with the company. The firm retrieves their lifetime value at a cost of c+δ. 

The second term within the brackets reflects profit contribution among the β(1-γ) fraction of
contacted would-be churners who do not accept the offer and leave the firm. The loss
from these customers is c, since they do not accept the offer. The third term within the
brackets reflects profit contribution among the (1-β) fraction of contacted customers who are not would-be churners. We assume these customers accept the offer and cost the company c+δ. These customers represent the wasted money for the firm. They were not going to churn yet the firm spent incentive money on them.

Note this formulation takes as given the percentage of the customer base to be
contacted (α). Implicitly, we are only concerned with the “false positives” represented by 1-β. 

In general, the firm might also be concerned with the percentage of customers
not contacted (1-α) who are churners and might have been retained (the “false
negatives”). 

There is undoubtedly an inverse relationship between α and β, i.e., in
contacting more customers, we are reaching into the lower deciles where a smaller
percentage of customers are would-be churners. 

To find an optimal α, one would have to recognize that larger α will decrease the false negatives (1-α) but increase the false
positives (1-β would get larger). 

In our example, we will assume α is specified at 10% - the company has decided, perhaps due to budget constraints, to contact 10% of its
customer base – its top decile of predicted churners.

The term β reflects the accuracy of the model, and is related to the concept of lift
as follows. Let:
β0 = The fraction of all the firm’s customers who will churn.

λ = “Lift” from the predictive model, i.e., how much more likely the
contacted group of customers is to churn relative to all the firm’s
customers. 

λ=1 would mean that the model provides essentially no
predictive power, since the targeted customers are no more likely
to churn than the population as a whole. 

λ=2 means that the targeted customers are twice as likely to churn as the population as
a whole. In our numerical example, we will use α=.10, 

so λ is “top-decile lift”.

Then, we can express β as:

β = λβ0 

Substituting equation (2) into equation (1) and re-arranging terms, we get:
П = Nα{ (γLVC+δ(1-γ))β0λ - δ - c }  (3)


The incremental gain in profit from a unit increase in predictive accuracy “λ” is the slope
of equation (3), namely:
  
GAIN = Nα{ (γLVC+δ(1-γ)) β0 }  (4)

Equation (4) tells us that the gains in profit arising from improved predictive accuracy of
the churn predictive model depend on the following factors:

• Size of the campaign (Nα): To the extent that company has a large customer base
and will contact many of them in the churn management campaign, the potential
gain due to increased predictive accuracy is larger.

• Higher customer lifetime value (LVC): The purpose of the campaign is to
recapture the lifetime value of would-be churners. To the extent that this value is
larger, predictive accuracy is more important.

• Higher incentive cost (δ): High incentive cost means there will be a lot of money
wasted if predictive accuracy is poor. Therefore, high incentive cost implies that
the gains to predictive accuracy will be increased.

• Higher success rate (γ): Since we presume LVC > δ, higher success rate, i.e.,
contacted would-be churners are likely to be retained by the incentive, means that
predictive accuracy is more important. This is because the expected benefit from
finding a would-be churner (γLVC) is higher.

• Higher base churn rate (β0): To the extent that customer churn is a big problem
(higher β0), higher predictive accuracy offers more of a gain in profits.

The above results provide interesting insights. Our purpose, however, is to attach
some plausible dollar values to the gains from higher predictive accuracy. We therefore
assume reasonable values for the parameters in equation (4) and calculate the gains in
profit from improved lift. In doing so, we consider the “typical” wireless
telecommunications company, because an anonymous firm in this industry provided the
customer data for the tournament. Accordingly, we assume:

N = 5,000,000. We assume the wireless company has 5,000,000
subscribers.
α = .10. We assume the company will contact 10% of its customers in
the churn management campaign.
δ = $50. We assume the company will offer a $50 rebate to all
targeted customers.
γ = .1, .3, or .5. There are no published statistics on how many wouldbe
churners accept a $50 offer and stay with the company. We use
three values, 10%, 30%, and 50%, to provide a reasonable range.
c = $0.50. We assume it costs 50 cents to contact customers to offer
them the $50 rebate. This could be done via a separate mailing
piece.
 11
β0 = .018. The average monthly churn rate for the customers in our data
is 1.80%, so we use this as the baseline churn level. Note that
1.8% monthly churn translates to 1-.98212 = 20% annual churn.

LVC = $1500, $2500, $4000. Monthly revenues per customer for the
typical telecommunications company are in the $40-$60 range. If
we use $40, a monthly churn rate of 1.8%, and a 5% annual
discount rate, the lifetime value of the customer is $1812. 
A heavy user customer might spend $100 per month, which would result in
an LVC of $4530. We use the values $1500, $2500, and $4000 as
reasonable numbers for our illustrative calculations.

$50, $65, $100 / month (12) * avg(m 1.87 = total revenue
(Average Value of a Sale) X (Number of Repeat Transactions) X (Average Retention Time in Months or Years for a Typical Customer)
An easy example would be the lifetime value of a gym member who spends $20 every month for 3 years. The value of that customer would be:
$20 X 12 months X 3 years = $720 in total revenue (or $240 per year)

Using the above assumptions, Table 1 displays the gains in profit from improving
lift λ by a tenth of a unit, i.e., from 2 to 2.1, etc. The table shows that even in the least
favorable scenario, customer lifetime value of $1500 and only a 10% success rate, a gain
in just a tenth of a point in lift results in $175,500 additional profit contribution. At the
other extreme, at an LVC of $4000 and a 50% success rate, a gain of a tenth of a point in
lift generates $1,822,500 additional profits. Of course the numbers depend importantly
on the lifetime value of the recovered customer and the success rate in preventing him or
her for churning. However, in all cases, a seemingly small increase in lift, say from 2 to
2.1, would be worth $100,000’s to the company. A gain of half a point, say from 2 to
2.5, would be worth five times that, easily in the range of $1,000,000.
[Table 1 Goes About Here]
The calculations demonstrate that with reasonable assumptions for the company
that provided the data for this tournament, it is easy to see how relatively small gains in
predictive accuracy can be worth $100,000’s in increased profits. Therefore, if the
entries to the tournament generate roughly the same lift, say all are close to λ=2, the
differences in lift we observe, while possibly statistically significant, are not managerially
significant. However, if the differences we observe are on the order of half a point or
more, the differences are managerially very important. 

 Note this calculation does not include the variable cost of providing service. Telecommunications
companies are saddled with huge fixed cost due to the investment they have made with infrastructure, so
we assume the goal of the company is revenue growth to cover these costs.



Two prediction criteria were used for each of the two validation databases,
resulting in four “contests” in all. The two prediction criteria were top decile lift and the
Gini coefficient. 

The top-decile lift (λ) was defined as the percentage among the 10% of
customers predicted to be most likely to churn who actually churned (β) divided by the
baseline churn rate (β0=.018) (see equation 2). 

Lift is probably the most commonly used
prediction criterion in predictive modeling, and its relevance is demonstrated by the profit
calculations in the previous section. Lift relates directly to profitability.

The second prediction coefficient, the Gini coefficient, has not been applied as
often in database marketing, although can be calculated from the cumulative lift curve,
which is commonly used. Figure 3 shows a cumulative lift curve. This tells us what
cumulative percentage of churners are accounted for by the x% of customers predicted to
be most likely to churn. Obviously one would want cumulative lift to be as high as
possible. 

For example, one would like the 25% of customers predicted most likely to
churn to account for 100% of churners if possible. Note the diagonally increasing line
with unit slope in Figure 3 is the random lift curve. If predictions are random, the top
25% of customers will account for 25% of churners.

The goal is to generate a lift curve as separated as possible from the random lift
curve. This is measured by the Gini coefficient – the area between an entry’s cumulative
lift curve and the random lift curve. To specify the Gini coefficient, define:
n = number of customers.

vi = % of churners who have predicted probability of churn equal to or
higher than customer i.

vˆi = % of customers who have predicted probability of churn equal to
or higher than customer i.

The Gini coefficient is then defined as (Alker 1965; Statistics.Com 2002):
SUM OF (2/N) (NEED MORE OF THIS)


The Gini coefficient can range from zero to one. Higher Gini reflects better separation
between the achieved lift curve and random lift

Note that top-decile lift λ focuses on lift
among the top 10% of customers, whereas Gini measures lift along the full continuum. It
is plausible that a given method might be very good at identifying the top candidates for
churn, but does not do as well on identifying the mid-range candidates. If that is the case,
Gini and λ will be relatively uncorrelated. 

```{r}
Prove statistical model difference with A/B test 
ggplot(final_set, aes(x=churn, y = something prob auc of all the folds)) +
  geom_boxplot()

t.test(x=auc or accuracy from 10 folds, data = model_comparison_set, alternative = "greater", mu = other 10 fold graph avg )

library(pwr)

pwr.anova.test(k=3,
               n=10,
               f=0.2,
               sig.level=0.05,
               power = NULL)

pwr.t.test(n=10,
           d = 0.2,
           sig.level=0.05,
           type = "two.sample",
           alternative = "greater",
           power = NULL)

K number of grioups
n number of ovs
f is effect size
```


Linear Regression to predict future revenue
```{r}
lm(avgmin ~ avgrev, data = tele_clean_rows)
R-Squared = how much of the variation is explains this month, as high as possible
F-Test whether R2 = 0, pvalue > 0.05 so our model rejects the null hypoth R squared is 0.


#the effect of the mean avgmin this month is statistifcally significant. A one-unit increase in the mean avgrev leads to a <coefficient> increase in the total avgrev this month.

yes <- lm(totcalls ~ avgrev, data = tele_clean)
summary(yes)
lm(avgqty ~ avgrev, data = final_training_set)
lm(change_mou ~ avgrev, data = final_training_set) 

# see which variables lead to increase/decrease revenue
tele_clean$Customer_ID <- NULL

nums <- unlist(lapply(tele_clean, is.numeric))
numeric_tele <- tele_clean[,nums]

index <- sample(1:nrow(numeric_tele), 3/4 * nrow(numeric_tele))
training <-numeric_tele[index,]
test <- numeric_tele[-index,]


lm_model <- lm(avgrev ~ .,data=training)
summary(yes)
yes$coefficients

# predict next month's running avg rev
test$predRev <- predict(lm_model, newdata = test)
test$churn <- tele_clean[-index,]$churn

test %>%
  filter(churn == 0) %>%
  summarize(non_churnPRED = sum(predRev), non_churnACTUAL = sum(avgrev))

test %>%
  filter(churn == 1) %>%
  summarize(actual_churn = sum(predRev),actual_churnACTUAL = sum(avgrev))
sum(test$avgrev)
```

```{r}
library(MASS)
# examine coefficients
index <- sample(1:nrow(tele_clean), 3/4 * nrow(tele_clean))
training <-tele_clean[index,]
test <- tele_clean[-index,]

model <- glm(churn ~ ., data = training, family = "binomial")
coef(model) %>% exp() %>% round(2)

# ON EACH MODEL
AIC <-stepAIC(model, trace = 0)
as.formula(summary(model)$call)

#install.packages("descr")
library(descr)
LogRegR2(model)
# McFadden
# Cox & Snell
# Nagelkerke
>0.2 is reasonable, 0.4 is good 0.5 is very good
Make a table for charts

test$predNew <- predict(model, newdata = test, type = "response")

#install.packages("SDMTools")
library(SDMTools)
confMatrixNew <- confusion.matrix(test$churn, test$predNew, threshold = 0.5)

True Negative (correct to return), False Negative
False-Postive,                     True Positive (correct to leave)

<- sum(diag(confMatrixNew)) / sum(confMatrixNew)

#find optimal threshold
Payoff = (customer returns because we sent $250 coupon) * True Negative - (customer predicted to to leave but returned ~$1000) * false Negative

Threshold   Accuracy  Payoff
0.5            0.8      60975
0.4            0.81     62000

payoffMatrix <- as.data.frame()

payoffMatrix <- data.frame(threshold = seq(from = 0.4, to = 0.6, by= 0.01), payoff = NA)
for(i in 1:length(payoffMatrix$threshold)) {
  confMatrix <- confusion.matrix(test$churn, test$predNew, threshold = payoffMatrix$threshold[i])
  payoffMatrix$payoff[i] <- confMatrix[1,1]* 50 + confMatrix[1,2] *(-50.5)
}
payoffMatrix


Cross validation
set.seed(1)

#####CROSS FOLD
install.packages("cvTools")
library(cvTools)
k=2
folds <- cvFolds(NROW(tele_clean), K=k)
tele_clean$holdoutpred <- rep(0,nrow(tele_clean))
tele_clean$fold <- rep(0,nrow(tele_clean))

for(i in 1:k){
  train <- tele_clean[folds$subsets[folds$which != i], ]
  validation <- tele_clean[folds$subsets[folds$which == i], ]
  
  newglm<- glm(churn~.,data=train,family="binomial")
  newpred <- predict(newglm, newdata=validation)
  tele_clean[folds$subsets[folds$which == i], ]$holdoutpred <- newpred
  tele_clean[folds$subsets[folds$which == i], ]$fold <- i
}
tele_clean$holdoutpred

ifelse(tele_clean$holdoutpred > 0.5, 1, 0)


tele_clean$holdoutpred



#cross validate

split into 10 sets, 1 will be test - use 10 for training and 1 for test

library(boot)
Acc03 <- function(r, pi=0){
  cm <- confusion.matrix(r,pi,threshol=0.5)
  acc <- sum(diag(cm)) / sum(cm)
  return(acc)
}

set.seed(1)
cv.glm(churnData, model, cost = Acc03, K = 6)$delta[1]


#INSERT PREDICTION INTO FINAL SET

```

```{r}
test$predNew <- predict(model, newdata = test, type = "response")
install.packages("ROCR")
require(ROCR)
pred <- prediction(test$predNew, test$churn)
perf <- performance(pred, "tpr","fpr")
plot(perf, main="ROC CURVE", colorize = T)

perf <- performance(pred, "lift", "rpp")
plot(perf, main="ROC CURVE", colorize = T)

liftvalues <- perf@y.values
liftvalues<-as.data.frame(liftvalues)
mean(liftvalues[-1,])
avglift = 1.18
```

```{r]}
#survival analysis - when people will make their next order

ggplot() +
  geom_histogram(aes(x= months), fill = churn) +
  facet_grid(~ churn) +
  theme(legend.position = "none")

