---
title: "capstoneModelling2"
author: "Jake Daniels"
date: "July 22, 2018"
output: html_document
---

# Part 4) Modelling

R - Logistic 
```{r}
set.seed(1)
# data split 75% train - 25% validate
index_train <- sample(1:nrow(final_set), 3/4 * nrow(final_set))
final_training_set <- final_set[index_train, ]
validation <- final_set[-index_train, ]

# model build
R_logistic_model <- glm(churn ~ ., family = "binomial", data = final_training_set)
  R_predictions <- predict(R_logistic_model, newdata = validation, type = "response")

# using 50% cutoff as our indicator someone will churn, can be reduced
  R_pred_cutoff_50 <- ifelse(R_predictions > 0.5, 1, 0)
  
# Constructing a confusion matrix
  R_conf_matrix_50 <- table(validation$churn, R_pred_cutoff_50) %>% confusionMatrix(positive='1')

R_conf_matrix_50
```
```{r}
model_name <- paste("glm(churn ~ ., family = 'binomial', data = final_training_set)")
subtitle <- paste("Logistic Regression in R")  
mplot_roc(validation$churn, R_predictions, model_name = model_name, subtitle = subtitle)
```
Caret - Logistic 10 Fold
```{r}
# train a model and summarize model
set.seed(1)
control <- trainControl(method="cv", number=10)
fit.glm <- train(churn~., data=final_training_set, method="glm", metric="Accuracy", trControl=control)

# estimate skill on validation dataset
set.seed(1)
fit.glm_pred_cutoff_50 <- predict(fit.glm, newdata=validation)

# Constructing a confusion matrix
  fit.glm_conf_matrix_50 <- table(validation$churn, fit.glm_pred_cutoff_50) %>% confusionMatrix(positive='1')

fit.glm_conf_matrix_50
```
```{r}
model_name <- paste("train(churn~., data=final_training_set, method='glm', metric='Accuracy', trControl=control)")
subtitle <- paste("10-Fold Logistic Regression with Caret")  
fit.glm_predictions <- predict(fit.glm, newdata=validation, type = "prob")
mplot_roc(validation$churn, fit.glm_predictions[,2], model_name = model_name, subtitle = subtitle)
```
Weka - logitBoost
```{r}
set.seed(1)
Weka_boost_model <- LogitBoost(churn ~ ., data=final_training_set)

Weka_boost_predictions <- predict(Weka_boost_model, newdata = validation, type = "probability")
  Weka_boost_pred_cutoff_50 <- ifelse(Weka_boost_predictions[,2] > 0.5, 1, 0)
  Weka_boost_conf_matrix_50 <- table(validation$churn, Weka_boost_pred_cutoff_50) %>% confusionMatrix(positive='1')
Weka_boost_conf_matrix_50
```
```{r}
model_name <- paste("LogitBoost(churn ~ ., data=final_training_set)")
subtitle <- paste("LogitBoost with Weka")  
mplot_roc(validation$churn, Weka_boost_predictions[,1], model_name = model_name, subtitle = subtitle)
```
Weka - Naive Bayes
```{r}
set.seed(1)
NB <- make_Weka_classifier("weka/classifiers/bayes/NaiveBayes")
weka_NB_model <- NB(churn ~ ., data=final_training_set)

Weka_NB_predictions <- predict(weka_NB_model, newdata = validation, type = "probability")
Weka_NB_pred_cutoff_50 <- ifelse(Weka_NB_predictions[,2] > 0.5, 1, 0)

Weka_NB_conf_matrix_503 <- table(validation$churn, Weka_NB_pred_cutoff_50) %>% confusionMatrix(positive='1')
Weka_NB_conf_matrix_503
```
```{r}
model_name <- paste("NB(churn ~ ., data=final_training_set)")
subtitle <- paste("Naive Bayes with Weka")  
mplot_roc(validation$churn, Weka_NB_predictions[,2], model_name = model_name, subtitle = subtitle)
```
Weka - Random Forest
```{r}
set.seed(1)
WekaForest <- make_Weka_classifier("weka/classifiers/trees/RandomForest")

Weka_forest_model <- WekaForest(churn ~ ., data=final_training_set)

Weka_forest_predictions <- predict(Weka_forest_model, newdata = validation, type = "probability")
Weka_forest_pred_cutoff_50 <- ifelse(Weka_forest_predictions[,2] > 0.5, 1, 0)

Weka_forest_conf_matrix_50 <- table(validation$churn, Weka_forest_pred_cutoff_50) %>% confusionMatrix(positive='1')
Weka_forest_conf_matrix_50
```
Visualize AUC
```{r}
model_name <- paste("WekaForest(churn ~ ., data=final_training_set)")
subtitle <- paste("Random Forest with Weka") 
frame4<- mplot_roc(validation$churn, Weka_forest_predictions[,2], model_name = model_name, subtitle= subtitle)
frame4
```
Visualize Density
```{r}
mplot_density <- function(tag, score, model_name = NA, subtitle = NA, 
                          save = FALSE, file_name = "viz_distribution.png") {
  require(ggplot2)
  require(gridExtra)

  if (length(tag) != length(score)) {
    message("The tag and score vectors should be the same length.")
    stop(message(paste("Currently, tag has",length(tag),"rows and score has",length(score))))
  }

  if (length(unique(tag)) != 2) {
    stop("This function is for binary models. You should only have 2 unique values for the tag value!")
  }
  normFunc <- function(x){(x-mean(x, na.rm = T))/sd(x, na.rm = T)}
  out <- data.frame(tag = as.character(tag),
                    score = as.numeric(score),
                    norm_score = normFunc(as.numeric(score)))
  
  p1 <- ggplot(out) + theme_minimal() +
    geom_density(aes(x = 100 * score, group = tag, fill = as.character(tag)), 
                 alpha = 0.6, adjust = 0.25) + 
    guides(fill = guide_legend(title="Churn")) + 
    xlim(0, 100) + 
    labs(title = "Score distribution for binary model",
         y = "Density by tag", x = "Predicted % to Churn") +
    scale_fill_manual(values=c("deepskyblue", "red"))
return(p1)
}
frame1 <- mplot_density(final_set$churn, final_set$holdoutpred)
frame1
```
Visualizie Bins
```{r}
mplot_cuts <- function(score, splits = 10, subtitle = NA, model_name = NA, 
                       save = FALSE, file_name = "viz_ncuts.png") {
  
  require(ggplot2)
  require(RColorBrewer)
  if (splits > 25) {
    stop("You should try with less splits!")
  }
  
  deciles <- quantile(score, 
                      probs = seq((1/splits), 1, length = splits), 
                      names = TRUE)
  deciles <- data.frame(cbind(Deciles=row.names(as.data.frame(deciles)),
                              Threshold=as.data.frame(deciles)))
  
  p <- ggplot(deciles, 
              aes(x = reorder(Deciles, deciles), y = deciles * 100, 
                  label = round(100 * deciles, 1))) + 
    geom_col(fill="deepskyblue") + 
    xlab('Data Intervals') + theme_minimal() + ylab('Predicted % to Churn') + 
    geom_text(vjust = 1.5, size = 3, inherit.aes = TRUE, colour = "white", check_overlap = TRUE) +
    labs(title = paste("Predicted % to Churn Binned in Intervals"))

  if(!is.na(subtitle)) {
    p <- p + labs(subtitle = subtitle)
  } 
  if(!is.na(model_name)) {
    p <- p + labs(caption = model_name)
  }
  if (save == TRUE) {
    p <- p + ggsave(file_name, width = 6, height = 6)
  }
  return(p)
}

frame3<- mplot_cuts(Weka_forest_predictions[,2])
frame3
```
Visualize Distribution
```{r}
library(RColorBrewer)

  df <- data.frame(validation$churn, Weka_forest_predictions[,2])
  npersplit <- round(nrow(df)/5)
  names <- df %>%
    mutate(quantile = ntile(Weka_forest_predictions[,2], 5)) %>% group_by(quantile) %>%
    summarise(n = n(), 
              max_score = round(100 * max(Weka_forest_predictions[,2]), 1), 
              min_score = round(100 * min(Weka_forest_predictions[,2]), 1)) %>%
    mutate(quantile_tag = paste0("",quantile,"~20%"))
  
  frame2 <- df %>%
    mutate(quantile = ntile(Weka_forest_predictions[,2], 5)) %>% 
    group_by(quantile, validation.churn) %>% tally() %>%
    ungroup() %>% group_by(validation.churn) %>% 
    arrange(desc(quantile)) %>%
    mutate(p = round(100*n/sum(n),2),
           cum = cumsum(100*n/sum(n))) %>%
    left_join(names, by = c("quantile")) %>%
    ggplot(aes(x = as.character(validation.churn), y = p, label = as.character(p),
               fill = as.character(quantile_tag))) + theme_minimal() +
    geom_col(position = "stack") +
    geom_text(size = 3, position = position_stack(vjust = 0.5), check_overlap = TRUE) +
    xlab("Did / Did Not Churn") + ylab("Total Percentage by Tag") +
    guides(fill = guide_legend(title=paste0("~",npersplit," p/split"))) +
    labs(title = "20% Splits Comparing Churn as Percentage") +
    scale_fill_brewer(palette = "Spectral", direction=-1)
  
  frame2
```
Full Visual
```{r}
grid.arrange(
      frame1, frame2, frame4, frame3,
      widths = c(1.3,1),
      layout_matrix = rbind(c(1,2), c(1,2), c(1,3), c(4,3)))
```

Calculate Lift
```{r}
#install.packages("ROCR")
library(ROCR)

pred <- prediction(Weka_forest_predictions[,2], validation$churn) 
perf <- performance(pred,"lift","rpp")
plot(perf, main="lift curve", colorize=T)
```

Highest Payoff Cutoff
```{r}
#install.packages("SDMTools")
library(SDMTools)

payoffMatrix <- data.frame(threshold = seq(from = 0.4, to = 0.6, by= 0.01), payoff = NA)
for(i in 1:length(payoffMatrix$threshold)) {
  confMatrix <- confusion.matrix(final_set$churn, final_set$holdoutpred, threshold = payoffMatrix$threshold[i])
  payoffMatrix$payoff[i] <- confMatrix[2,2]* 50 + confMatrix[2,1] *(-50.5)
}
payoffMatrix
```

Staistical Significance
```{r}
t.test(x=c(66.2,65.45,66.7), data = tele_clean, alternative = "greater", mu =62)



binom.test(7451, 7451+7667, p=0.5, alternative = "two.sided")
mcnemar.test(table(basic_test_set$churn, basic_pred_cutoff),table(validation$churn, Weka_forest_pred_cutoff_50))
write.arff(final_set, "final_set.arff")
```
Evaluating Model Value
```{r}
Gain

```

Save Model
```{r}
# save the model to disk
saveRDS(Weka_forest_model, "./Weka_forest_model.rds")
 
# load the model
final_model <- readRDS("./Weka_forest_model.rds")
print(final_model)
# make a predictions on "new data" using the final model
final_predictions <- predict(final_model, validation$churn)
confusionMatrix(final_predictions, validation$Class, positive='1')
```





Other caret models
```{r}
# linear algorithms
set.seed(7)
fit.lda <- train(churn ~ ., data=DstTrainModel, method="lda", metric=metric, trControl=control)

# CART
set.seed(7)
fit.cart <- train(churn ~ ., data=DstTrainModel, method="rpart", metric=metric, trControl=control)

# kNN
set.seed(7)
fit.knn <- train(churn ~ ., data=DstTrainModel, method="knn", 
                 metric=metric, trControl=control, preProcess = c("center","scale"), tuneLength = 5)

# Random Forest
set.seed(7)
fit.rf <- train(churn ~ ., data=DstTrainModel, method="rf", metric=metric, trControl=control)

# Gradient Boost Machine (GBM)
set.seed(7)
fit.gbm <- train(churn ~ ., data=DstTrainModel, method="gbm", 
                 metric=metric, trControl=control, verbose=FALSE)
```

Compare Results
```{r}
results <- resamples(list(
    glm=fit.glm, 
    lda=fit.lda, 
    cart=fit.cart,
    gbm=fit.gbm
))
    #knn=fit.knn,
    #rf=fit.rf,
summary(results)
# compare accuracy of models
dotplot(results)


AccCalc <- function(TestFit, name) {
    # prediction 
    DstTestModelClean <- DstTestModel
    DstTestModelClean$churn <- NA
    predictedval <- predict(TestFit, newdata=DstTestModelClean)
    
    # summarize results with confusion matrix
    cm <- confusionMatrix(predictedval, DstTestModel$churn)
    
    # calculate accuracy of the model
    Accuracy<-round(cm$overall[1],2)
    acc <- as.data.frame(Accuracy)
 
    roc_obj <- roc(DstTestModel$churn, as.numeric(predictedval))
    acc$Auc <- auc(roc_obj)
    
    acc$FitName <- name
    return(acc)
}

accAll <- AccCalc(fit.glm, "glm")
accAll <- rbind(accAll, AccCalc(fit.lda, "lda"))
accAll <- rbind(accAll, AccCalc(fit.cart, "cart"))
#accAll <- rbind(accAll, AccCalc(fit.knn, "knn"))
#accAll <- rbind(accAll, AccCalc(fit.rf, "rf"))
accAll <- rbind(accAll, AccCalc(fit.gbm, "gbm"))
rownames(accAll) <- c()
arrange(accAll,desc(Accuracy))
```
```{r}


```{r}
#install.packages("cvTools")
library(cvTools)

#you may need to restart R and run these lines first to increase your memory limit: 
# library(rJava) 
# options(java.parameters = "-Xmx2048m")

k=4
folds <- cvFolds(NROW(final_set), K=k)
final_set$holdoutpred <- rep(0,nrow(final_set))
final_set$fold <- rep(0,nrow(final_set))

for(i in 1:k){
  train <- final_set[folds$subsets[folds$which != i], ]
  validation <- final_set[folds$subsets[folds$which == i], ]
  
Weka_forest_model <- WekaForest(churn ~ ., data=train)
  newpred <- predict(Weka_forest_model, newdata=validation, type = "probability")
  final_set[folds$subsets[folds$which == i], ]$holdoutpred <- newpred[,2]
  final_set[folds$subsets[folds$which == i], ]$fold <- i
}
final_set$holdoutpred

final_set$actualpred <- ifelse(final_set$holdoutpred > 0.5, 1,0)
Weka_forest_conf_matrix_51 <- table(final_set$churn, final_set$actualpred) %>% confusionMatrix(positive='1')
Weka_forest_conf_matrix_51


```

